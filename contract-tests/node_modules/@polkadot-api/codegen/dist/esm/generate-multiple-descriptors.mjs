import { getLookupFn, getChecksumBuilder } from '@polkadot-api/metadata-builders';
import { mapReferences, mapEntryPointReferences } from '@polkadot-api/metadata-compatibility';
import { mapObject } from '@polkadot-api/utils';
import { generateDescriptors, capitalize } from './generate-descriptors.mjs';
import { generateTypes } from './generate-types.mjs';
import { getUsedTypes } from './get-used-types.mjs';
import { knownTypes } from './known-types.mjs';
import { getTypesBuilder, defaultDeclarations } from './types-builder.mjs';
import { applyWhitelist } from './whitelist.mjs';

const generateMultipleDescriptors = (chains, paths, options = {}) => {
  const chainData = chains.map((chain) => {
    const metadata = options.whitelist ? applyWhitelist(chain.metadata, options.whitelist) : chain.metadata;
    const lookup = getLookupFn(metadata);
    const builder = getChecksumBuilder(lookup);
    const { checksums, types: types2, entryPoints } = getUsedTypes(lookup, builder);
    return {
      ...chain,
      lookup,
      builder,
      checksums,
      types: types2,
      entryPoints,
      knownTypes: {
        ...knownTypes,
        ...chain.knownTypes
      }
    };
  });
  resolveConflicts(chainData);
  const types = mergeTypes(chainData);
  const declarations = defaultDeclarations();
  const chainFiles = chainData.map(
    (chain) => generateDescriptors(
      chain.lookup,
      types.checksumToIdx,
      getTypesBuilder(
        declarations,
        chain.lookup,
        chain.knownTypes,
        chain.builder
      ),
      chain.builder,
      chain.key,
      paths,
      chain.genesis
    )
  );
  const descriptorsFileContent = generateDescriptorValuesContent(
    Object.fromEntries(
      chainFiles.map((file, i) => [chainData[i].key, file.descriptorValues])
    )
  );
  const commonFileContent = `const table = new Uint8Array(128);
for (let i = 0; i < 64; i++) table[i < 26 ? i + 65 : i < 52 ? i + 71 : i < 62 ? i - 4 : i * 4 - 205] = i;
export const toBinary = (base64: string) => {
  const n = base64.length,
    bytes = new Uint8Array((n - Number(base64[n - 1] === '=') - Number(base64[n - 2] === '=')) * 3 / 4 | 0);
  for (let i2 = 0, j = 0; i2 < n;) {
    const c0 = table[base64.charCodeAt(i2++)], c1 = table[base64.charCodeAt(i2++)];
    const c2 = table[base64.charCodeAt(i2++)], c3 = table[base64.charCodeAt(i2++)];
    bytes[j++] = c0 << 2 | c1 >> 4;
    bytes[j++] = c1 << 4 | c2 >> 2;
    bytes[j++] = c2 << 6 | c3;
  }
  return bytes;
}`;
  return {
    commonFileContent,
    descriptorsFileContent,
    metadataTypes: types,
    descriptorTypesFiles: chainFiles.map((file) => ({
      content: file.descriptorTypes,
      exports: file.exports
    })),
    typesFileContent: generateTypes(
      declarations,
      paths,
      new Set(chainFiles.map((x) => x.commonTypeImports).flat())
    ),
    publicTypes: getPublicTypes(declarations.variables)
  };
};
function getPublicTypes(variables) {
  return Array.from(variables.values()).filter((variable) => variable.type.startsWith("Enum<")).map((variable) => variable.name);
}
function resolveConflicts(chainData) {
  const usedNames = /* @__PURE__ */ new Map();
  chainData.forEach(
    (chain) => chain.checksums.forEach((checksum) => {
      const known = chain.knownTypes[checksum];
      if (!known) return;
      const { name } = known;
      if (!usedNames.has(name)) {
        usedNames.set(name, /* @__PURE__ */ new Map());
      }
      if (!usedNames.get(name).has(chain.key)) {
        usedNames.get(name).set(chain.key, /* @__PURE__ */ new Set());
      }
      usedNames.get(name).get(chain.key).add(checksum);
    })
  );
  const conflictedNames = Array.from(usedNames.entries()).filter(([_, chainToChecksums]) => {
    const checksums = new Set(
      Array.from(chainToChecksums.values()).flatMap((v) => [...v])
    );
    if (checksums.size === 1) return false;
    const allAreTheSame = Array.from(chainToChecksums.values()).every(
      (chainChecksums) => chainChecksums.size === checksums.size
    );
    if (allAreTheSame) return false;
    return true;
  }).map(([name]) => name);
  conflictedNames.forEach((name) => {
    const nameChecksums = Array.from(
      new Set(
        Array.from(usedNames.get(name)?.values() ?? []).flatMap(
          (v) => Array.from(v)
        )
      )
    );
    const checksumMaxPriority = nameChecksums.map((checksum) => ({
      checksum,
      priority: chainData.map((chain) => chain.knownTypes[checksum]?.priority ?? 0).reduce((a, b) => Math.max(a, b), 0)
    }));
    const absoluteMax = checksumMaxPriority.map((v) => v.priority).reduce((a, b) => Math.max(a, b), 0);
    const checksumsLowPriority = checksumMaxPriority.filter(
      (v) => v.priority !== absoluteMax
    );
    const checksumsChangingName = checksumsLowPriority.length === checksumMaxPriority.length - 1 ? checksumsLowPriority : checksumMaxPriority;
    chainData.forEach(
      (chain) => checksumsChangingName.forEach(({ checksum }) => {
        if (!chain.knownTypes[checksum]) return;
        chain.knownTypes[checksum] = {
          name: capitalize(chain.key) + name,
          priority: chain.knownTypes[checksum].priority
        };
      })
    );
  });
}
function mergeTypes(chainData) {
  const typedefs = [];
  const entryPoints = [];
  const loookupToTypedefIdx = /* @__PURE__ */ new Map();
  const checksumToIdx = /* @__PURE__ */ new Map();
  chainData.forEach(({ types, entryPoints: chainEntryPoints, checksums }) => {
    for (const entry of types.entries()) {
      const [checksum, value] = entry;
      if (loookupToTypedefIdx.has(checksum)) continue;
      loookupToTypedefIdx.set(checksum, typedefs.length);
      typedefs.push([value, checksums]);
    }
    for (const entry of chainEntryPoints.entries()) {
      const [checksum, value] = entry;
      if (checksumToIdx.has(checksum)) continue;
      checksumToIdx.set(checksum, entryPoints.length);
      entryPoints.push([value, checksums]);
    }
  });
  const updatedTypedefs = typedefs.map(
    ([typedef, checksums]) => mapReferences(typedef, (id) => loookupToTypedefIdx.get(checksums[id]))
  );
  const updatedEntryPoints = entryPoints.map(
    ([entryPoint, checksums]) => mapEntryPointReferences(
      entryPoint,
      (id) => loookupToTypedefIdx.get(checksums[id])
    )
  );
  return {
    typedefs: updatedTypedefs,
    entryPoints: updatedEntryPoints,
    checksumToIdx
  };
}
function generateDescriptorValuesContent(descriptorValues) {
  const usages = {};
  const countUsages = (obj) => Object.entries(obj).forEach(([key, value]) => {
    usages[key] = usages[key] ?? 0;
    usages[key]++;
    if (typeof value === "object") countUsages(value);
  });
  countUsages(descriptorValues);
  const tokens = [];
  const tokenToIdx = {};
  const minifyKeys = (obj) => Object.fromEntries(
    Object.entries(obj).map(([key, value]) => {
      const newValue = typeof value === "number" ? value : minifyKeys(value);
      if (usages[key] <= 1) return [key, newValue];
      if (!(key in tokenToIdx)) {
        tokenToIdx[key] = tokens.length;
        tokens.push(key);
      }
      return [tokenToIdx[key], newValue];
    })
  );
  const minified = mapObject(descriptorValues, minifyKeys);
  const getTreeKey = (tree) => Object.entries(tree).sort(([a], [b]) => a.localeCompare(b)).map(
    ([key, value]) => `[${key}:${typeof value === "object" ? getTreeKey(value) : value}]`
  ).join("");
  const findCommonTrees = (values) => {
    const treeUsages = {};
    const keys = values.map(
      (obj) => mapObject(obj, (tree) => {
        const key = getTreeKey(tree);
        treeUsages[key] = treeUsages[key] ?? 0;
        treeUsages[key]++;
        return key;
      })
    );
    const commonTrees2 = [];
    const keyToCommonTree = {};
    values.forEach(
      (obj, i) => Object.entries(obj).forEach(([objKey, tree]) => {
        const key = keys[i][objKey];
        if (treeUsages[key] > 1) {
          if (!(key in keyToCommonTree)) {
            keyToCommonTree[key] = commonTrees2.length;
            commonTrees2.push(tree);
          }
          obj[objKey] = keyToCommonTree[key];
        }
      })
    );
    return commonTrees2;
  };
  const commonTrees = findCommonTrees(
    Object.keys(Object.values(minified)[0]).flatMap(
      (type) => Object.values(minified).map((d) => d[type])
    )
  );
  const data = JSON.stringify([minified, commonTrees, tokens]);
  return `
    const [minified, commonTrees, tokens] = JSON.parse(\`${data}\`);

    const replaceTokens = <T>(obj: Record<string | number, T>): Record<string, T> =>
      Object.fromEntries(
        Object.entries(obj).map(([key, value]) => {
          const unwrappedValue =
            typeof value === "object" ? replaceTokens(value as any) : value
          const numericKey = Number(key)
          if (Number.isNaN(numericKey)) {
            return [key, unwrappedValue]
          }
          return [tokens[numericKey], unwrappedValue]
        }),
      ) as Record<string, T>
    const tokenizedCommonTrees = commonTrees.map(replaceTokens)

    const unwrap = (
      obj: Record<string, object | number>,
      depth: number,
    ): Record<string, object> =>
      depth === 0
        ? (obj as Record<string, object>)
        : Object.fromEntries(
            Object.entries(obj).map(([key, value]) => [
              key,
              unwrap(
                typeof value === "object" ? value : tokenizedCommonTrees[value],
                depth - 1,
              ),
            ]),
          )

    const getChainDescriptors = (key: string) =>
      unwrap(replaceTokens(minified[key]), 2)

    ${Object.keys(descriptorValues).map(
    (key) => `export const ${capitalize(key)} = getChainDescriptors("${key}")`
  ).join("\n")}
  `;
}

export { generateMultipleDescriptors };
//# sourceMappingURL=generate-multiple-descriptors.mjs.map
